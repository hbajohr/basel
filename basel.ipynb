{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbajohr/anadiplosis/blob/main/WORKSHOP_GPT_2_Untrained_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_7n70B2j2sF"
      },
      "source": [
        "#Seminar Basel - GPT-2\n",
        "\n",
        "\n",
        "This notebook lets you generate text from one of the four OpenAI GPT-2 models. These models are not fine-tuned.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  I. Setup:\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4197225-79e6-47ee-b2f6-53c9a7861cbb"
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are four released sizes of GPT-2. All can be used to generate text, but only the first two can be finetuned; your memory might be limited to only the smaller models.\n",
        "There are four released sizes of GPT-2. All can be used to generate text, but only the first two can be finetuned; your memory might be limited to only the smaller models.\n",
        "\n",
        "* `124M` (default): the \"small\" model.\n",
        "* `355M`: the \"medium\" model.\n",
        "* `774M`: the \"large\" model.\n",
        "* `1558M`: the \"extra large\" model."
      ],
      "metadata": {
        "id": "hyQ74JBOSmlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"124M\"   # type in the model size, e.g. \"124M\"\n",
        "gpt2.download_gpt2(model_name=model_name)\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "metadata": {
        "id": "zD-S0ZBPSlrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "# II. Generate Text From The Pretrained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UltS-coKweUw"
      },
      "source": [
        "##**Task:**\n",
        "\n",
        "*  Explore the effects of the parameter values; concentrate on prefix, temperature and top_k. Collect your findings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"AI will write literature when\",   #\n",
        "              length=20,                                # number of tokens to generate\n",
        "              truncate='\\n',                            # stop after line break in output\n",
        "              temperature=1,                            #\n",
        "              top_k=10,                                 #\n",
        "              nsamples=5,                               # how many texts to generate\n",
        "              batch_size=5                              # how many samples simulatneously (increases speed)\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dOxs51yt7H5"
      },
      "source": []
    }
  ]
}
